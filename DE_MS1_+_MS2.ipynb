{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DE_MS1 + MS2",
      "provenance": [],
      "collapsed_sections": [
        "OYvqMplAG2x-",
        "SI0cTfqYG2yA",
        "MBlDTtZ3G2yB",
        "Ctcx0_-wG2yC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUEul4tZ68Zp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "t8cid-sUG2x-"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from IPython.display import Javascript\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "OYvqMplAG2x-"
      },
      "source": [
        "# Loading Data sets B\n",
        "This functions loads all the data sets available\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "AARGzOV5G2x_"
      },
      "source": [
        "def load_data_sets():\n",
        "    life_expectancy_df = pd.read_csv(\"data/Life-Expectancy-Data.csv\")\n",
        "    countries_df = pd.read_csv(\"data/250-Country-Data.csv\")\n",
        "    happiness_dfs = {\"2015\": 0, \"2016\": 1, \"2017\": 2, \"2018\": 3, \"2019\": 4}\n",
        "    for key in happiness_dfs.keys():\n",
        "        happiness_dfs[key] = pd.read_csv(\n",
        "            \"data/Happiness_Dataset/{year}.csv\".format(year=key))\n",
        "    return life_expectancy_df, countries_df, happiness_dfs"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "_MW6Y_D2G2yA"
      },
      "source": [
        " life_expectancy_df, countries_df, happiness_dfs = load_data_sets()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "j-gho6AhG2yA"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "SI0cTfqYG2yA"
      },
      "source": [
        "# Normalizing Dataframe column names C\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mZghayT4G2yB"
      },
      "source": [
        "def rename_columns(df):\n",
        "    df = df.rename(str.strip, axis='columns')\n",
        "    df = df.rename(columns=lambda name:  \" \".join(\n",
        "        w[:1].upper() + w[1:] for w in name.split()))\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "life_expectancy_df = rename_columns(life_expectancy_df)\n",
        "countries_df = rename_columns(countries_df)\n",
        "\n",
        "for key in happiness_dfs.keys():\n",
        "   happiness_dfs[key] = rename_columns(happiness_dfs[key])\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "MBlDTtZ3G2yB"
      },
      "source": [
        "# Helper functions to explore the data D\n",
        "The below cell defines helper functions that will plot all relevant data about each column in a given data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NVSUeYThG2yB"
      },
      "source": [
        "def contstruct_string_data(df, column, type):\n",
        "    rows, columns = df.shape\n",
        "    unique_values = df[column].nunique()\n",
        "    present_values = df[column].count()\n",
        "    missing_values = rows - present_values\n",
        "    missing_values_percentage = np.round((missing_values/rows)*100, 2)\n",
        "    present_values_percentage = np.round((present_values/rows)*100, 2)\n",
        "    mean = \"N/A\"\n",
        "    std = \"N/A\"\n",
        "    if(type != \"object\"):\n",
        "      mean = np.round(np.mean(df[column]), 2)\n",
        "      std = np.round(np.std(df[column]), 2)\n",
        "\n",
        "    most_common = df[column].mode()[0]\n",
        "    data = [(\"Unique Values\", unique_values),\n",
        "            (\"Present Values\", present_values),\n",
        "            (\"Present Values %\", present_values_percentage),\n",
        "            (\"Missing Values\", missing_values),\n",
        "            (\"Missing Values %\", missing_values_percentage),\n",
        "            (\"Most Common\", most_common),\n",
        "            (\"Mean\", mean),\n",
        "            (\"STD\", std)\n",
        "            ]\n",
        "    return data\n",
        "\n",
        "\n",
        "def display_column_data(df, column, type):\n",
        "    data = contstruct_string_data(df, column, type)\n",
        "    print(\"========================= {column} data =========================\".format(column=column))\n",
        "    for name, value in data:\n",
        "        percentage_sign = \"%\" if \"%\" in name else \"\"\n",
        "        print(\"{name}: {value}{percentage_sign}\".format(name=name, value=value,percentage_sign=percentage_sign))\n",
        "    return data\n",
        "\n",
        "\n",
        "def plot_column(df, column, index, type):\n",
        "    graph = plt.figure()\n",
        "    graph.suptitle(\"{column} Statistics\".format(column=column))\n",
        "    if(type==\"object\"):\n",
        "      graph = sns.histplot(data=df, x=column)\n",
        "    data = display_column_data(df, column, type)\n",
        "    unique_values = df[column].nunique()\n",
        "    if(unique_values > 25 and type == \"object\"):\n",
        "        graph.set_xticklabels(\"\")\n",
        "    if(type != \"object\"):\n",
        "      graph = sns.displot(df[column],kde=True)\n",
        "      box_plot = plt.figure()\n",
        "      box_plot = sns.boxplot(x=df[column])\n",
        "    plt.show()\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "def transform_data(data):\n",
        "    data_dict = []\n",
        "    for row in data:\n",
        "        row_dict = {}\n",
        "        for column in row:\n",
        "            column_name, value = column\n",
        "            row_dict[column_name] = value\n",
        "        data_dict.append(row_dict)\n",
        "    return data_dict\n",
        "\n",
        "# Plots all column data for a given df\n",
        "def plot_column_data(df):\n",
        "    data_types = df.dtypes\n",
        "    # print(data_types)\n",
        "    data = []\n",
        "    for index, column in enumerate(df):\n",
        "        column_data = plot_column(df, column, index, data_types[index])\n",
        "        data.append(column_data)\n",
        "    transformed_data = transform_data(data)\n",
        "    column_data_df = pd.DataFrame.from_records(transformed_data)\n",
        "    column_data_df = column_data_df.set_index(df.columns)\n",
        "    print(\"========================= Columns Summary =========================\")\n",
        "    return column_data_df\n",
        "\n",
        "\n",
        "    # data_df = pd.DataFrame.from_(data)\n",
        "    # print(data_df,\"DATA\")\n",
        "\n",
        "\n",
        "def explore_df(df):\n",
        "    rows, columns = df.shape\n",
        "    #print(rows, columns, \"OKK??\")\n",
        "    print(df[0:5])\n",
        "    info = df.info()\n",
        "    return plot_column_data(df)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "AiLyN2b_G2yC"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Ctcx0_-wG2yC"
      },
      "source": [
        "# General Helper Functions E"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "NRJSvvcrG2yC"
      },
      "source": [
        "def examine_missing_column(df, group_by, column):\n",
        "  index = df[column].isnull()\n",
        "  grouped_df = df[index].groupby(group_by).sum()[:][column]\n",
        "  return grouped_df\n",
        "\n",
        "def iterative_impute(df,columns,column):\n",
        "    imputer = IterativeImputer(random_state=0)\n",
        "    df = df[columns]\n",
        "    imputer = imputer.fit(df)\n",
        "    return imputer.transform(df)\n"
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}